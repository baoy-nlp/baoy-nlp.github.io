## About Me

<!--This is Yu Bao (é²å®‡). My name in Chinese Pinyin has two interesting extensions, one means rainstorm (ðŸŒ§) and the other means abalone (ðŸŸ). I prefer the former one, as it looks very powerful. Actually, my name comes from "Staying together through thick and thin (fÄ“ng yÇ” tÃ³ng zhÅu)" because I also have an older brother named [Feng Bao](https://scholar.google.com/citations?user=U0cuO94AAAAJ&hl=zh-CN).-->

<!-- I am currently a Research Scientist at ByteDance Seed, specializing in Large Language Model (LLM) research with a focus on multilingual translation, LLM alignment, and multimodal modelingâ€”with recent work spanning end-to-end simultaneous speech-to-speech translation, self-play-driven multilingual translation without parallel data, and building efficient large-scale multilingual translation LLMs. -->
I am currently a Research Scientist at ByteDance Seed, specializing in research on Large Language Model (LLM), AI for Science (AI4S), and Natural Language Processing (NLP).

Before this, I completed my Ph.D. at the [Natural Language Processing Group](http://nlp.nju.edu.cn/homepage/) of [Nanjing University](https://grawww.nju.edu.cn/main.htm), co-supervised by Prof. [Shujian Huang](http://nlp.nju.edu.cn/huangsj/) and Prof. [Jiajun Chen](https://cs.nju.edu.cn/chenjiajun/). During my doctoral studies, I interned at ByteDance AI Lab under the mentorship of Prof. [Zhou Hao](https://zhouh.github.io/) and Prof. [Lei Li](https://lileicc.github.io/), where I laid the groundwork for generative modeling research, including non-autoregressive text generation and latent variable-based parallel text generation.
<!--I hold a Bachelor's Degree from the School of Science at [Northeast Forestry University](https://www.nefu.edu.cn/).-->

<!--My work bridges multiple areas, with recent focus on their intersection in multilingual and multimodal scenarios:
- **Generative Modeling:** Autoregressive and Non-autoregressive frameworks (e.g., diffusion models)
- **Structure-Aware:** Graph-based representations (e.g., molecules), tree-structure (syntax tree), and sequential data (plain text) modeling
- **Multimodality:** Natural Language Sequence and Syntax, 1D-2D-3D Molecule, Audio-Text, etc..-->

<!--All of my research interests focus on deep generative models. During my Ph. D. studies and internships at ByteDance AI Lab, I worked on structure and sequence modeling in deep generative models, focusing on machine translation and natural language generation. Now, as a member of ByteDance Research, my focus has turned to AI for Science, especially structure-based drug design.-->

<!--<center><a href="mailto:nlp.baoy@gmail.com">[Email]</a> <a href="./files/baoy_CV.pdf">[CV]</a></center>-->
## News
<span style="color:red;">We're hiring! Whether you're seeking an internship or a full-time role, join us to build cutting-edge AI systems! Feel free to reach out via <a href="mailto:baoyu.001@bytedance.com">baoyu.001@bytedance.com</a> for the [Top Seed Program](https://seed.bytedance.com/zh/topseed?view_from=homepage_tab) (internships & full-time positions available) or [JD sites](https://job.toutiao.com/s/_e74JFvZtw4) directly.</span> 
<!--The ByteDance Seed Team is actively recruiting exceptional talents passionate about LLM researchâ€”especially in multilingual translation, LLM alignment, and multimodal modeling (e.g., end-to-end simultaneous speech-to-speech translation, zero-resource translation).
*We're hiring! The ByteDance Seed Team is actively seeking exceptional talents in LLM. Feel free to contact me and apply via <a href="mailto:baoyu.001@bytedance.com">baoyu.001@bytedance.com</a> for the **Top Seed Internship** program.*-->


<!-- ### Awards

- 2022, Excellent Doctoral Paper Award, JiangSu Association of Artificial Intelligence.
- 2020, Outstanding Ph.D. Candidate, Nanjing University
- 2019, Artificial Intelligence Scholarship, Nanjing University
- 2019, Outstanding Graduate Student, Nanjing University -->

## Selected Publications/Preprints <a href="https://scholar.google.com/citations?authuser=1&user=TqMb6nMAAAAJ">[Full list]</a> 

\[name*: equal contributions\] \[<ins>name</ins>: interns/students I mentored\]

<!--**<u>AI for Science (Structure-based Drug Design)</u>**

- Xiangxin Zhou\*â€ , Xiwei Cheng\*â€ , Yuwei Yang, **Yu Bao**, Liang Wang, Quanquan Gu, [DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization](https://arxiv.org/abs/2403.13829), ICLR 2024.
- Jiaqi Guan\*â€ , Xiangxin Zhou\*â€ , Yuwei Yang, **Yu Bao**, Jian Peng, Jianzhu Ma, Qiang Liu, Liang Wang, Quanquan Gu, [DecompDiff: Diffusion Models with Decomposed Priors for Structure-Based Drug Design](https://arxiv.org/abs/2403.07902), ICML 2023.-->

<!-- **<u>Deep Generative Models</u>** -->
<!-- **Natural Language Processing and Text Generation** -->
<!--3. Wei Zou, <ins>Sen Yang</ins>, **Yu Bao**, Shujian Huang, Jiajun Chen, Shanbo Cheng, [Trans-Zero: Self-Play Incentivizes Large Language Models for Multilingual Translation Without Parallel Data](https://arxiv.org/abs/2504.14669), ACL 2025 Findings.
4. <ins>Shimao Zhang</ins>, **Yu Bao**, Shujian Huang, [EDT: Improving Large Language Models by Entropy-based Dynamic Temperature Sampling](https://arxiv.org/pdf/2403.14541.pdf), Preprint 2024..
3. <ins>Xiwei Cheng</ins>\*, <ins>Xiangxin Zhou</ins>\*, Yuwei Yang, **Yu Bao**, Quanquan GU, Decomposed direct preference optimization for structure-based drug design, Preprint 2024.-->
<!--7. Lihua Qian, Hao Zhou, **Yu Bao**, Mingxuan Wang, Lin Qiu, Weinan Zhang, Yong Yu, Lei Li, [Glancing Transformer for Non-Autoregressive Neural Machine Translation](https://aclanthology.org/2021.acl-long.155.pdf), ACL 2021.-->
1. ByteDance Seed Team, [Seed LiveInterpret 2.0: End-to-end Simultaneous Speech-to-speech Translation with Your Voice](https://arxiv.org/abs/2507.17527), [[Homepage](https://seed.bytedance.com/zh/seed_liveinterpret) \| [Demo](https://console.volcengine.com/ark/region:ark+cn-beijing/experience/voice?type=SI)], Preprint 2025.
2. ByteDance Seed Team, [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618), [[HuggingFace](https://huggingface.co/collections/ByteDance-Seed/seed-x-6878753f2858bc17afa78543) \| [Demo](https://huggingface.co/spaces/ByteDance-Seed/Seed-X)], Preprint 2025.
3. <ins>Xiangxin Zhou</ins>\*, <ins>Xiwei Cheng</ins>\*, Yuwei Yang, **Yu Bao**, Liang Wang, Quanquan Gu, [DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization](https://arxiv.org/abs/2403.13829), ICLR 2024.
4. <ins>Jiaqi Guan</ins>\*, <ins>Xiangxin Zhou</ins>\*, Yuwei Yang, **Yu Bao**, Jian Peng, Jianzhu Ma, Qiang Liu, Liang Wang, Quanquan Gu, [DecompDiff: Diffusion Models with Decomposed Priors for Structure-Based Drug Design](https://arxiv.org/abs/2403.07902), ICML 2023.
5. <ins>Min Liu</ins>, **Yu Bao**, Chengqi Zhao, Shujian Huang, [Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation](https://arxiv.org/abs/2303.17910), AAAI 2023.
6. **Yu Bao**, Hao Zhou, Shujian Huang, Dongqi Wang, Lihua Qian, Xinyu Dai, Jiajun Chen, Lei Li, [latent-GLAT: Glancing at Latent Variables for Parallel Text Generation](https://baoy-nlp.github.io/files/Latent_GLAT.pdf), ACL 2022.
7. **Yu Bao**, Shujian Huang, Tong Xiao, Dongqi Wang, Xinyu Dai, Jiajun Chen, [Non-Autoregressive Translation by Learning Target Categorical Codes](https://aclanthology.org/2021.naacl-main.458.pdf), NAACL-HLT 2021.
8. Jiahuan Li*, **Yu Bao**\*, Shujian Huang, Xinyu Dai, Jiajun Chen, [Explicit Semantic Decomposition for Definition Generation](https://virtual.acl2020.org/paper_main.65.html), ACL 2020.
9. **Yu Bao**, Hao Zhou, Jiangtao Feng, Mingxuan Wang, Shujian Huang, Jiajun Chen, Lei Li, [PNAT: Non-Autoregressive Transformer by Position Learning](https://arxiv.org/abs/1911.10677), Preprint 2019. 
10. **Yu Bao**\*, Hao Zhou*, Shujian Huang, Lei Li, Lili Mou, Olga Vechtomova, Xinyu Dai, Jiajun Chen, [Generating Sentences from Disentangled Syntactic and Semantic Spaces](https://aclanthology.org/P19-1602.pdf), ACL 2019.

<!-- 6. Shimao Zhangâ€ , Yu Bao, Shujian Huang, [EDT: Improving Large Language Models by Entropy-based Dynamic Temperature Sampling](https://arxiv.org/pdf/2403.14541.pdf), Preprint 2024.
7. Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, Mingxuan Wang, [DiNoiSer: Diffused Conditional Sequence Learning by Manipulating Noises](https://arxiv.org/abs/2302.10025), Transaction of ACL (2024).
8. Yu Bao, Shujian Huang, Hao Zhou, Lei Li, Xinyu Dai, Jiajun Chen, [Unsupervised Paraphrasing via Syntactic Template Sampling](https://www.sciengine.com/SSI/doi/10.1360/SSI-2021-0065;JSESSIONID=81ea9517-be4e-4348-81b7-739c29cb09ac), SCIENTIA SINICA Informationis (2022).
9. Jiahuan Li*, Yu Bao*, Shujian Huang, Xinyu Dai, Jiajun Chen, [Explicit Semantic Decomposition for Definition Generation](https://virtual.acl2020.org/paper_main.65.html), ACL 2020.
10. Yu Bao*, Hao Zhou*, Shujian Huang, Lei Li, Lili Mou, Olga Vechtomova, Xinyu Dai, Jiajun Chen, [Generating Sentences from Disentangled Syntactic and Semantic Spaces](https://aclanthology.org/P19-1602.pdf), ACL 2019. -->
<!-- **Non-Autoregressive Text Generation** -->
<!-- 1. Min Liuâ€ , Yu Bao, Chengqi Zhao, Shujian Huang, [Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation](https://arxiv.org/abs/2303.17910), AAAI 2023.
2. Yu Bao, Hao Zhou, Shujian Huang, Dongqi Wang, Lihua Qian, Xinyu Dai, Jiajun Chen, Lei Li, [latent-GLAT: Glancing at Latent Variables for Parallel Text Generation](https://baoy-nlp.github.io/files/Latent_GLAT.pdf), ACL 2022.
3. Lihua Qian, Hao Zhou, Yu Bao, Mingxuan Wang, Lin Qiu, Weinan Zhang, Yong Yu, Lei Li, [Glancing Transformer for Non-Autoregressive Neural Machine Translation](https://aclanthology.org/2021.acl-long.155.pdf), ACL 2021.
4. Yu Bao, Shujian Huang, Tong Xiao, Dongqi Wang, Xinyu Dai, Jiajun Chen, [Non-Autoregressive Translation by Learning Target Categorical Codes](https://aclanthology.org/2021.naacl-main.458.pdf), NAACL-HLT 2021.
5. Yu Bao, Hao Zhou, Jiangtao Feng, Mingxuan Wang, Shujian Huang, Jiajun Chen, Lei Li, [PNAT: Non-Autoregressive Transformer by Position Learning](https://arxiv.org/abs/1911.10677), Preprint 2019. -->

<!-- ### Invited Talks

- Grammar Learning and Its Application for Molecular Design, Tsinghua University AIR, Oct. 2022.
- latent-GLAT: Glancing at Latent Variables for Parallel Text Generation, CIPSC & PaperWeekly & MLNLP, ACL-IJCAI-SIGIR, Apr. â€” May. 2022.
- Research and Development of Parallel Text Generation, ByteDance AI Lab, Oct. 2021.
- Advice for Undergraduate Students, Northeast Forestry University, Nov. 2020. -->

## Professional Services

**<u>Area Chair of</u>**

- [ACL Rolling Review](https://aclrollingreview.org/reviewing) 2025-
- The 1st GenBio Workshop on New Frontiers of Generative AI and Biology at NeurIPS 2023

**<u>Journal Reviewer of</u>**

- IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)
- IEEE Transactions on Neural Networks and Learning Systems (TNNLS)
- Journal of Artificial Intelligence Research (JAIR)

**<u>PC Member/Reviewer of</u>**

- International Conference on Machine Learning (ICML) 2023-
- Annual Conference on Neural Information Processing Systems (NeurIPS) 2022-
- International Conference on Learning Representations(ICLR) 2022-
- North American Chapter of the Association for Computational Linguistics (NAACL) 2022-
- ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) 2022-
- AAAI Conference on Artificial Intelligence (AAAI) 2022-
- Annual Meeting of the Association for Computational Linguistics (ACL) 2021-
- Conference on Empirical Methods in Natural Language Processing (EMNLP) 2021-
- The Chinese National Conference on Computational Linguistics (CCL) 2022
- The CCF Conference on Natural Language Processing and Chinese Computing (NLPCC) 2022
- International Joint Conferences on Artificial Intelligence (IJCAI) 2020

---

<center>
  <iframe src="https://calendar.google.com/calendar/embed?height=300&wkst=1&bgcolor=%23ffffff&ctz=Asia%2FShanghai&mode=AGENDA&showTabs=0&showTitle=1&showNav=0&showPrint=0&showTz=0&showCalendars=0&title=Schedule&src=d2VpZmVuZ2xpdXl1ZUBnbWFpbC5jb20&src=Z3IwY2l0a3NpMjQ5b3RhbGxuYWVjY2ZhamxlNmlkMm1AaW1wb3J0LmNhbGVuZGFyLmdvb2dsZS5jb20&color=%237986CB&color=%23E67C73" style="border-width:1" width="600" height="300" frameborder="0" scrolling="no">
  </iframe>
</center>

<center>
  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=353&t=tt&d=RXIJvl1M9HfHAiXc7AJe-qo0sHke2u_46ckL7Qp5HrY&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
</center>


<!--
**baoy-nlp/baoy-nlp** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
